---
title: "What even is Hyperpop?"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    storyboard: true

---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(spotifyr)
library(compmus)
library(plotly)
library(dplyr)
source("TempogramsClass.R")
```
Latest homework {.storyboard}
=====================================

### Homework 11 Part 1 [DANCE MUSIC BACKGROUND]

```{r}
cook <- get_tidy_audio_analysis("0YAywhODGdHhWxuvFFhjE3")

cook |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic() +
  ggtitle("Tempogram of Beautiful by A. G. Cook")

```

***
<h2>A Proto-Hyperpop classic</h2>
Dance music is no stranger to the precursors of the hyperpop "genre". A steady beat pattern that is easy to dance to paired with cute vocal chops was one of the classic formulas to make a hyperpop banger in 2015, or how it was called around then: "bubblegum bass". The genre was inspired by Pop and Dance songs, and artists in the realm started making music around the idea of experimenting with the boundaries of these genres.

A. G. Cook, creator of the label PC Music has been claimed to be one of the most important figures of the early days of the scene alongside peers like SOPHIE, EASYFUN, Danny L. Harle, umru, etc. For this reason, I thought it would be a great idea to look at the spectrogram of Cook's single "Beautiful", a dance-pop track that was bundled with many other proto-hyperpop bangers in the <a href="https://open.spotify.com/album/1nJD8cgitrI7sWC4i3Ox32?si=3401937641da4591" target=”_blank”>"PC Music, Vol. 1"</a> compilation.

The tempogram shows a steady beat of 140 bpm. Around 1min and 15 seconds in we can see a fluctuation that might be caused by the removal of the main vocal and the incorporation risers and sound effects. I could imagine the code having some trouble with this section due to the lack of regular musical onsets that could help establish a steady beat. After this part however, the line comes back to a steady 140bpm. The reason why I chose this song for a tempogram is because I knew that the kick drum pattern didn't start until this part of the song (1min 30 secs), and I wanted to see if the code would have major problems beforehand. As we can see, aside from that brief section and the outro (which removes the drums), the tempogram implies the clear influence that Dance music had in the genre. For the next tempograms, we will see if the influence is still clear in newer hyperpop songs.

### Homework 11 Part 2 [Dance influence prevails]

```{r}
dream <- get_tidy_audio_analysis("68MQeN7xm2ooBG1o3BIS39")

dream |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic() +
  ggtitle("Tempogram of Dream Analysis by patchymate")

```

***
To see how the influence of dance music has prevailed across the years in the genre, I wanted to study a song that came out in 2023. This song was part of the feedBack playlist, and not the hyperpop playlist, but I thought it would be interesting to see how the genre is shifting into new territories while still bringing its "hyper" roots that at one point first came from Dance music.

This song is Dream Analysis by patchymate, a catchy pop song where the main protagonists are guitar and vocals. I considered this song for analysis because it also incorporates a classic dance four-on-the-floor kick pattern. I thought this would make the tempogram into a clear straight line, similar to the previous case. However, I noticed that, even though there's a predominant bpm at 120, the line seems jagged and wiggly at some points. For example, I find it hard to understand the ramp up in tempo around 50 seconds, since the kick pattern stays the same and there's no significant changes. Around 90 seconds in, the line becomes wiggly again, but this time I had a better idea why: This is the bridge of the song, which in this case changes the beat and sound selection. The last few seconds of the song make the line irregular again due to the removal of the kick pattern and the introduction of granular pads and sound effects. This made me think: What would happen if I used a song where the latter type of sounds was predominant across the whole track? The next and last tempogram of my portfolio will explore exactly that.

### Homework 11 Part 3 [Granular experiments]

```{r}
### BRAKENCE PREPARATION EXERCISE N07 (OPTIMIZED)

p_plot <- readRDS(file = "data/prep_week_11.RDS")

p_plot

```

***
<h2>Breaking the code</h2>
If there's one thing found across most hyperpop tracks, it has to be the crazy sound design and experimental electronic sounds all over the place. Granular sound design is one of the many techniques that these artists use, you can learn more about it in <a href="https://www.youtube.com/watch?v=dseIXf-Bis0" target=”_blank”>this</a> short video by the artist and producer phritz. After seeing what happens in the tempogram with Granular sound design in the previous tempogram, I wanted to see what would happen with a song where the complicated sound design of hyperpop takes the leading role.

<a href="https://open.spotify.com/track/3P4qX48fiwsQXEBhOgvRt0?si=20ffc037eb324efa" target=”_blank”>preparation exercise no.7 (trembling)</a> by <a href="https://open.spotify.com/artist/4kqFrZkeqDfOIEqTWqbOOV?si=P3EbxkU7Sje0-VAyAqap9g target=”_blank”">brakence</a> is a very special song in the genre because of its sound design and tempo changes, and therefore the perfect candidate to try to break the code for generating tempograms. The main conclusions I can draw from this experiment is that the sound design in this song made it really hard for the code to dictate a clear BPM and it rather shows a deconstructed spectrum of possible tempi across the duration of the song. Despite this, it is relevant to say that it seems to pick a ramping up tempo across all the duration of the track. This surprised me even more: It seems like the song is a constant crescendo from the very beginning. I knew I could expect a ramp-up section halfway through the song because I remembered it from listening to the song, however, I didn't expect the whole song to be constantly increasing the tempo. Finally, the tempo becomes a steady 95-ish bpm during the track outro that creates a seemless transition to the next song in brakence's album, <a href="https://open.spotify.com/track/718Z7VJDi0YRr7vXrdB0Uv?si=8db0ccda026b474d" target=”_blank”>cbd</a>

Past, Present and Future of hyperpop {.storyboard}
=====================================

### It's all about being loud and energetic

```{r}
hyper <- get_playlist_audio_features("", "4fg8XveWZ4xQatc4mHLsyb")
classic <- get_playlist_audio_features("", "3WWGBxHe4bAyKFq1DAnszd")
feed <- get_playlist_audio_features("", "7oEgNy93qnlcm361HgrXrN")
sound <-get_playlist_audio_features("", "7DrJ92Lc9UaVB1rKM2UGsg")


loud <-
  bind_rows(
    hyper |> mutate(category = "Hyperpop (Spotify editorial)"),
    classic |> mutate(category = "Hyperpop Classics (Spotify editorial)"),
    feed |> mutate(category = "feedBack (Spotify editorial)"),
    sound |> mutate(category = "The Sound of Hyperpop"),
  )


  ggplot(loud, aes(x = energy, y = loudness, alpha = tempo, color = category, text = track.name)) +
  geom_point(size = 2, fill = "black") +

  scale_color_brewer(
    type = "qual",
    palette = "Spectral",
    name = "Playlist"
    ) +
    scale_alpha_continuous(
      guide = "none"
    ) +
    theme_classic() +
    ggtitle("Loudness and energy distribution across Hyperpop playlists")
  
    
ggplotly()
```
***
With this plot I wanted to study the overall loudness and energy across every song in my corpus. I decided to use the geom_point visualization so I could see every song represented with a circle. I also used plotly to identify each song with its name and its respective color associated with each playlist. The tempo of the songs is also associated with its transparency, but it is not the focus study of this plot.

As you can see, the big bulk of songs is concentrated around the -10dB and -4dB range. My interpretation is that this is not a defining characteristic of the “hyperpop sound”, because probably most of the songs uploaded to streaming services get mastered around that level. However, it caught my eye how a great handful of songs are above 0dB, which made me think that hyperpop can easily reach the clipping territory. I will further study some of these songs to see if I can find any more useful information that stands out about them.

In terms of energy, it seems like the range is extremely bast: It is mainly concentrated above 0.50, but covers almost every value. I argue that this is prooves that hyperpop songs don’t need to be very energetic to be part of the playlists, and even relaxing ballads such as Himera’s “I Look Up to the Sky & Remember How Much You Mean to Me” can be considered part of the “Sound of hyperpop”. However, It seems like once we start exploring the actual hyperpop communities picks (such as sleepy zone and FORM), the song choices deviate more from the bulk of energetic tracks that most editorial playlist recognize as energetic.

### Nightcore influence, high bpm

```{r}
ggplot(loud, aes(x=tempo, fill = as.factor(category))) +
  geom_density(alpha = 0.5) +
  ggtitle("BPM distribution across playlists")

ggplotly()
```
***
One of the main attributes of the modern hyperpop sound is its influence from early internet music. In the early days of media sharing platforms such as YouTube, the genre Nightcore was born from uploads of sped up versions of famous pop songs. Hyperpop drinks a lot from this era of the internet, with high pitched vocals, instruments and fast tempos that easily embrace the early days of internet music consumption.

As this is another key element of the “hyperpop sound”, I wanted to see if it coorelates to the data that I could find. In the resulting plot, you can see how there is a noticeable peak around 140-145 bpm where most of the songs reside. There is a secondary area around 80-90 bpm, which at first surprised me because I was not expecting such result across every playlist. After working on these plots for several days, I stumbled upon a track whose tempo value indicated 77bpm, however, this song feels quite faster to me. The song is “Hollywood Baby” by 100 gecs, and after seeing this phenomenon, I came to the conclusion that many of these tracks in the lower tempo range were having its bpm divided by two. The 100 gecs song has a bpm of 154, but the spotify API interprets it as 77, which is in practice the same.

With this outlier exploration, I argue that the spotify API is not too reliable giving 100% accurate bpm measures, seeing how most of them get halved in the process. I wouldn’t say this plot is useful for giving us an insight into the “hyperpop sound”. However, as I stated previously, tempo is a very historically important thing to this community, so I tought it could be still worth exploring and keeping this plot in my storyboard.

### Key usage across time

```{r}

```

Chromograms {data-navmenu="The hyperpop sound"}
=====================================

### Chart AA

```{r}
####### HOLLYWOOD BABY
baby <-
  get_tidy_audio_analysis("48ElaQLYuOaybqagIlPxpU") |> # Hollywood Baby
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
baby |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()

####### SPOILED LITTLE BRAT
brat <-
  get_tidy_audio_analysis("724utiMbqUfT1g3tqbfQYu") |> # 
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
brat |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()


```

***
Commentary WIP

Structure analysis {data-navmenu="The hyperpop sound" .storyboard}
=====================================

### The clear pop stucture
```{r}
# SELF SIMILARITY SELFDESTRUCT TORR

torr <-
  get_tidy_audio_analysis("0JEViMA9EhoTE501kxvJMU") |> # 
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

torr |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

***
The prefix "Hyper" slapped into the "pop" umbrella genre implies a clear pop influence into this type the hyerpop genre. One of the attributes that make pop music, popular, its the structure of the song. That's why, for this self-similarity plot I decided to see if a typical hyperpop song follows the classic pops structure of Verse-chorus-verse-chorus-bridge-chorus.

This is selfdestruct by torr. When I first created this plot, the pop stucture was clear at to me first sight. There's a relatively easy to discern structure (a diagonal line) that repeats three time across the song. While listening to the track I realized that this is the chorus, and the sections inbetween are verses. Right before the 100 seconds mark we can see a greener section that underlies the bridge, a section of pop songs characterized by changes in chord progression, lyrics and in timbre. After this, the chorus comes back one last time, incorporating new elements that weren't there in its previous itterations.

Overall, this plot helped me understand what Spotify means by "Hyperpop": If we strip down other elements such as sound design, we are left what essentialy is a pop song. 


### What about an ambient section?

```{r}
###### SELF SIMILARITY DRY LAND

dry <-
  get_tidy_audio_analysis("7j7nOY7xZ7fpSVAKT4qz4b") |> # 
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

dry |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

***

Dry land 2001 by underscores is an example of a hyperpop song with an unusual structure, the song starts as a bass centered pop songs about tornados, and seemengly transitions into a 7 minute long ambient piece. With this self-similarity plot I wanted to see this ambient section appears in the plot. We can distinguish two clear sections: Before and after 150 seconds.

Before this timestamp, the song retains its pop structure, and we can see some patterns that repeat during this time and delineate this type of songwriting characterized by verses and choruses.From 150secs on, we can see the appearance of a new pattern: Several parallel lines emerge and sustain through time. This is clearly the start of the ambient section, with looping guitar patterns that repeat until the 7 minute mark. It is interesting to see how a song with such an unconventional stucture can be bundled up in a collection of pop songs characterized with short song durations and more overall pop influenced sturctures thought the whole track. 

This ambient section is an example of how the "hyperpop" sound goes beyond pop: These artists are not afraid to experiment and include an ambient section into their silly pop song, which clearly caught the eyes of the music industry and spotify's genre-creating playlist.

Keygrams and chordograms {data-navmenu="The hyperpop sound" .storyboard}
=====================================

### Homeswitcher keygram

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

### CHORDGRAM OF AN ARCHETYPE: HOMESWITCHER

home <-
  get_tidy_audio_analysis("3wGDs4CbpDqpsTYyN5pe8o") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

home |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Keygram of Homeswitcher by Jane Remover")
```

***
For this keygram I decided to analyse “homeswitcher” by Jane Remover, an archetype of the hyperpop genre that greatly influenced the genre merely two years ago. I also decided to analyse it because it is one of the few tracks in my corpus where the loudness level is above 0dB.

The track is F#min, but its clarity seems to differ depending on the section of the song. Around 40seconds in, the code seems to have a harder time telling the key, and even C#min seems to be darker for a few seconds. My guess is that the reason why the key becomes less obvious in these sections is because they are the loudest, and coincidentally incorporate a very noisy sub bass into the mix.

### Broken Friendship Bracelet chordogram
```{r}
friend <-
  get_tidy_audio_analysis("5tJAGoIXg3ZKX7W6unLGMv") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

friend |>
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "cosine",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Chordogram of Broken Friendship Bracelet by Himera")
```

***
For this second plot, I analysed the chordogram of Broken Friendship Bracelet by Himera, a track that is mainly composed of a repeating arpeggio that varies and incorporates more elements as the song progresses. Around 50 seconds in, we can see a shift from the first section that lived in the D7~C7 area towards the C#min~F#min area. This shift is very noticeable in the track with a change in sound selection that lead more towards trance music.

Tempogram? {data-navmenu="The hyperpop sound"}
=====================================

### Chart DD

```{r}
print("Helloooo this is a test")
```

